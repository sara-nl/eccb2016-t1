{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left\" src=\"images/spark.png\" />\n",
    "<img style=\"float: right\" src=\"images/surfsara.png\" />\n",
    "<hr style=\"clear: both\" />\n",
    "\n",
    "# Counting kmers with Apache Spark\n",
    "\n",
    "In our second notebook we will look at genomics data and count the numer of occurences of specific subsequences in the reads.\n",
    "\n",
    "_You can edit the cells below and execute the code by selecting the cell and press Shift-Enter. Code completion is supported by use of the Tab key._\n",
    "\n",
    "During the exercises you may want to refer to the [PySpark documentation](https://spark.apache.org/docs/1.6.1/api/python/pyspark.html#pyspark.RDD) for more information on possible transformations and actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialize Spark\n",
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "if not 'sc' in globals(): # This Python 'trick' makes sure the SparkContext sc is initialized exactly once\n",
    "    conf = SparkConf().setMaster('local[*]')\n",
    "    sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  RDD from a FASTA file\n",
    "\n",
    "We will start by creating an RDD from a FASTA file. We will read this using the `sc.textFile` method we also used in the first notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "\n",
    "reads = sc.textFile(\"file:////home/jovyan/work/data/blast/input/CAM_SMPL_GS108.fa\")\n",
    "\n",
    "pp.pprint(reads.take(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we are able to read the FASTA file, but the division in records is incorrect. The metadata and sequence data of a single read are now split over two separate records. The clean solution to this would be to write a custom InputFormat in Java or Scala. For simplicity in this tutorial we will do some text munching in Spark to get the same effect.\n",
    "\n",
    "## Remove metadata\n",
    "\n",
    "In this case we are not interested in the metadata. We select only the sequence data by adding an index number to all the records and use a [`filter`](https://spark.apache.org/docs/1.6.1/api/python/pyspark.html#pyspark.RDD.filter) to select only the odd-numberd records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indexed_reads = reads.zipWithIndex()\n",
    "\n",
    "pp.pprint(indexed_reads.take(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create an RDD 'indexed_sequences' from' indexed_reads' that only contains the records with an odd index.\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "indexed_sequences = indexed_reads.filter(lambda x: x[1] % 2 == 1)\n",
    "### END SOLUTION\n",
    "\n",
    "sequences = indexed_sequences.keys().cache()\n",
    "\n",
    "pp.pprint(sequences.take(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending WordCount: BaseCount\n",
    "\n",
    "Now that we have our input data in the format we want we can start to do something with it. Our first exercise is a variation on the WordCount we did in the first notebook. This time we will not count words, but the individual bases in the sequences.\n",
    "\n",
    "Hint: the easiest way in Python to split a string `s` into characters is: `list(s)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create an RDD 'bases' from 'sequences' containing all the individual bases (letters)\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "bases = sequences.flatMap(lambda s: list(s))\n",
    "### END SOLUTION \n",
    "\n",
    "pp.pprint(bases.take(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make key-value pairs and sum using reduceByKey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create an RDD 'basecount' 'from bases' with (base, #occurences) pairs\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "basecounts = bases.map(lambda b: (b, 1)).reduceByKey(lambda a,b: a + b)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we know the number of records in this RDD is very small (5), it is safe to call `collect` on the RDD and print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pp.pprint(basecounts.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending BaseCount: KmerCount\n",
    "\n",
    "Lets make it a bit more interesting.\n",
    "\n",
    "Select all substrings of length k. We have written a helper function for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sliding(seq, size):\n",
    "    result = []\n",
    "    for i in range(0, len(seq) - size + 1):\n",
    "        result.append(seq[i:i + size])\n",
    "    return result\n",
    "\n",
    "sliding(\"GAGATCTCCTGTGGTGTCCTTGGTCATAGTGATTTGCTCCTACAA\", 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an RDD with all the subsequences of length 21."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "kmers = sequences.flatMap(lambda s: sliding(s, 21))\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "kmercounts = kmers.map(lambda x: (x, 1)).reduceByKey(lambda x,y: x + y)\n",
    "### END SOLUTION\n",
    "kmercounts.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use takeOrdered to get the 10 most frequent 21-mers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "top10 = kmercounts.takeOrdered(10, key=lambda x: -x[1])\n",
    "### END SOLUTION\n",
    "pp.pprint(top10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we look at the distribution of 21-mers. x-axis the number of occurences of a 21-mer, y-axis the number of 21-mers that occur x times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### BEGIN SOLUTION\n",
    "kmerdist = kmercounts.map(lambda x: (x[1], 1)).reduceByKey(lambda x, y: x + y)\n",
    "### END SOLUTION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmerdistsorted = kmerdist.map(lambda x: (x[1], x[0])).sortByKey(True).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = kmerdistsorted.keys().collect()\n",
    "y = kmerdistsorted.values().collect()\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.yscale('log')\n",
    "plt.title(\"kmer distribution\")\n",
    "plt.xlabel(\"kmer matches\")\n",
    "plt.ylabel(\"genome wide frequency\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
